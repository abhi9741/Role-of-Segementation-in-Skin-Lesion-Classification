{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1637135402711,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "XNzV65iZY-ZO",
    "outputId": "fc029527-f8cd-4723-ec88-6b7a7c75c061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1637135404136,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "Ud23ReXTbCaS",
    "outputId": "10b88f15-4745-4eed-9e70-e9f3909db2bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/ISIC_Data_Segmentation\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/ISIC_Data_Segmentation/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1637135405540,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "t06msS0dhUK-",
    "outputId": "03e17ede-8cd3-4f11-be69-05a3746f0ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mlogs\u001b[0m/  \u001b[01;34mtrained_models\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1637135406609,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "fx7Bei47hU07"
   },
   "outputs": [],
   "source": [
    "#Import all dependencies\n",
    "\n",
    "import os\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1637135409279,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "_dGX0i6phft6",
    "outputId": "d1a1bc5c-f5c5-415d-aed4-c21f7f69103c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'test', 'val']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4162,
     "status": "ok",
     "timestamp": 1637135414918,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "agj2VMGlhiU6",
    "outputId": "a80079e5-3b76-41a1-813c-fd9577a4d33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images:\t 323 \t Groundtruth Masks:\t  323\n",
      "Validation Images:\t 46 \t Groundtruth Masks:\t  46\n",
      "Testing Images: \t 89 \t Groundtruth Masks:\t  89\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Images:\\t\",(len(os.listdir(r\"data/train/images\"))),\"\\t\",\"Groundtruth Masks:\\t \",((len(os.listdir(r\"data/train/masks\")))))\n",
    "print(\"Validation Images:\\t\",(len(os.listdir(r\"data/val/images\"))),\"\\t\",\"Groundtruth Masks:\\t \",((len(os.listdir(r\"data/val/masks\")))))\n",
    "print(\"Testing Images: \\t\",(len(os.listdir(r\"data/test/images\"))),\"\\t\",\"Groundtruth Masks:\\t \",((len(os.listdir(r\"data/test/masks\")))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1071,
     "status": "ok",
     "timestamp": 1637135418007,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "0iEVMMRAhs2a",
    "outputId": "689a62c4-1ec6-45b5-a358-abe07b495e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image:  RGB\n",
      "training ground truth image:  RGB\n",
      "test image:  RGB\n",
      "validation image:  RGB\n",
      "validation ground truth image:  RGB\n"
     ]
    }
   ],
   "source": [
    "#check image mode\n",
    "img = os.listdir('data/train/images')[0]\n",
    "with PIL.Image.open('data/train/images/'+img) as img : \n",
    "  print(\"train image: \",img.mode)\n",
    "\n",
    "img = os.listdir('data/train/masks')[0]\n",
    "with PIL.Image.open('data/train/masks/'+img) as img :\n",
    "  print(\"training ground truth image: \",img.mode)\n",
    "\n",
    "img = os.listdir('data/test/images')[0]\n",
    "with PIL.Image.open('data/test/images/'+img) as img :\n",
    "  print(\"test image: \",img.mode)\n",
    "\n",
    "\n",
    "img = os.listdir('data/val/images')[0]\n",
    "with PIL.Image.open('data/val/images/'+img) as img :\n",
    "  print(\"validation image: \",img.mode)\n",
    "\n",
    "img = os.listdir('data/val/masks')[0]\n",
    "with PIL.Image.open('data/val/masks/'+img) as img :\n",
    "  print(\"validation ground truth image: \",img.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 293531,
     "status": "ok",
     "timestamp": 1637097068550,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "CKvPK0cpjYMv"
   },
   "outputs": [],
   "source": [
    "#Convert from grayscale to RGB (R=G=B=gray)\n",
    "temp = ['train','val']\n",
    "for repo in temp :\n",
    "  for image in os.listdir(\"data/\"+repo+\"/masks\"):\n",
    "      with PIL.Image.open(\"data/\"+repo+\"/masks/\"+image) as img :\n",
    "        rgbimg = PIL.Image.new(\"RGB\", img.size)\n",
    "        rgbimg.paste(img)\n",
    "        rgbimg.save(\"data/\"+repo+\"/masks/\"+image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3977,
     "status": "ok",
     "timestamp": 1637097522186,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "7na_TLC0kluX",
    "outputId": "65e4f333-ecec-4d9d-c2dd-fb6050e00626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image:  RGB\n",
      "training ground truth image:  RGB\n",
      "test image:  RGB\n",
      "validation image:  RGB\n",
      "validation ground truth image:  RGB\n"
     ]
    }
   ],
   "source": [
    "#validating everything is in RGB & not in RGBA or L\n",
    "\n",
    "img = os.listdir('data/train/images')[0]\n",
    "img = PIL.Image.open('data/train/images/'+img)\n",
    "print(\"train image: \",img.mode)\n",
    "\n",
    "img = os.listdir('data/train/masks')[0]\n",
    "img = PIL.Image.open('data/train/masks/'+img)\n",
    "print(\"training ground truth image: \",img.mode)\n",
    "\n",
    "img = os.listdir('data/test/images')[0]\n",
    "img = PIL.Image.open('data/test/images/'+img)\n",
    "print(\"test image: \",img.mode)\n",
    "\n",
    "img = os.listdir('data/val/images')[0]\n",
    "img = PIL.Image.open('data/val/images/'+img)\n",
    "print(\"validation image: \",img.mode)\n",
    "\n",
    "img = os.listdir('data/val/masks')[0]\n",
    "img = PIL.Image.open('data/val/masks/'+img)\n",
    "print(\"validation ground truth image: \",img.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 26186,
     "status": "ok",
     "timestamp": 1637135452082,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "KC51NvtgmCmv"
   },
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, root ,train=True, transform = None):\n",
    "        Dataset.__init__(self)\n",
    "        images_dir = os.path.join(root,'images')\n",
    "        images = os.listdir(images_dir)\n",
    "        self.images = [os.path.join(images_dir, k) for k in images]\n",
    "        self.images.sort()\n",
    "        if train:\n",
    "            masks_dir = os.path.join(root,'masks')\n",
    "            masks = os.listdir(masks_dir)\n",
    "            self.masks = [os.path.join(masks_dir, k) for k in masks]\n",
    "            self.masks.sort()\n",
    "\n",
    "        self.transforms = transform\n",
    "        self.train = train\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        \n",
    "        image = Image.open(image_path).resize([512,512])\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        image = image\n",
    "        if self.train :\n",
    "            mask_path = self.masks[index]\n",
    "            mask = Image.open(mask_path).resize([512,512])\n",
    "            if self.transforms is not None:\n",
    "                mask = self.transforms(mask)\n",
    "                mask = mask.mean(dim=0).view(1,512,512)\n",
    "                mask[mask>0] = 0\n",
    "                mask[mask<0] = 1\n",
    "                \n",
    "            return image, mask\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1637135452931,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "jzzaaNIDmJWz"
   },
   "outputs": [],
   "source": [
    "#Loss Functions\n",
    "\n",
    "import torch\n",
    "\n",
    "def dice_loss(pred, target):\n",
    "    \"\"\"This definition generalize to real valued pred and target vector.\n",
    "This should be differentiable.\n",
    "    pred: tensor with first dimension as batch\n",
    "    target: tensor with first dimension as batch\n",
    "    \"\"\"\n",
    "    #target[target==0] = -1\n",
    "\n",
    "    smooth = 1.\n",
    "\n",
    "    # have to use contiguous since they may from a torch.view op\n",
    "    iflat = pred.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "\n",
    "    return 1 - ((2. * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "        \n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse as ifilterfalse\n",
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n",
    "    \"\"\"\n",
    "    IoU for foreground class\n",
    "    binary: 1 foreground, 0 background\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        intersection = ((label == 1) & (pred == 1)).sum()\n",
    "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n",
    "        if not union:\n",
    "            iou = EMPTY\n",
    "        else:\n",
    "            iou = float(intersection) / union\n",
    "        ious.append(iou)\n",
    "    iou = mean(ious)    # mean accross images if per_image\n",
    "    return 100 * iou\n",
    "\n",
    "\n",
    "def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n",
    "    \"\"\"\n",
    "    Array of IoU for each (non ignored) class\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        iou = []    \n",
    "        for i in range(C):\n",
    "            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n",
    "                intersection = ((label == i) & (pred == i)).sum()\n",
    "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n",
    "                if not union:\n",
    "                    iou.append(EMPTY)\n",
    "                else:\n",
    "                    iou.append(float(intersection) / union)\n",
    "        ious.append(iou)\n",
    "    ious = map(mean, zip(*ious)) # mean accross images if per_image\n",
    "    return 100 * np.array(ious)\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    logits = 1. - logits\n",
    "    labels = 1. - labels\n",
    "    #------------------#\n",
    "\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
    "                          for log, lab in zip(logits, labels))\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * Variable(signs))\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "class StableBCELoss(torch.nn.modules.Module):\n",
    "    def __init__(self):\n",
    "         super(StableBCELoss, self).__init__()\n",
    "    def forward(self, input, target):\n",
    "         neg_abs = - input.abs()\n",
    "         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "         return loss.mean()\n",
    "\n",
    "\n",
    "def binary_xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Cross entropy loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    logits, labels = flatten_binary_scores(logits, labels, ignore)\n",
    "    loss = StableBCELoss()(logits, Variable(labels.float()))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --------------------------- MULTICLASS LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_softmax(probas, labels, only_present=False, per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), only_present=only_present)\n",
    "                          for prob, lab in zip(probas, labels))\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), only_present=only_present)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, only_present=False):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "    \"\"\"\n",
    "    if probas.numel() == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return probas * 0.\n",
    "    C = probas.size(1)\n",
    "    \n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    for c in range(C):\n",
    "        fg = (labels == c).float() # foreground for class c\n",
    "        if only_present and fg.sum() == 0:\n",
    "            continue\n",
    "        errors = (Variable(fg) - probas[:, c]).abs()\n",
    "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
    "        perm = perm.data\n",
    "        fg_sorted = fg[perm]\n",
    "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n",
    "    return mean(losses)\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    B, C, H, W = probas.size()\n",
    "    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = (labels != ignore)\n",
    "    vprobas = probas[valid.nonzero().squeeze()]\n",
    "    vlabels = labels[valid]\n",
    "    return vprobas, vlabels\n",
    "\n",
    "def xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Cross entropy loss\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n",
    "\n",
    "\n",
    "# --------------------------- HELPER FUNCTIONS ---------------------------\n",
    "def isnan(x):\n",
    "    return x != x\n",
    "    \n",
    "    \n",
    "def mean(l, ignore_nan=True, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1637135452932,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "WreaVSitmnBF"
   },
   "outputs": [],
   "source": [
    "#Unet Model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import autograd\n",
    "\n",
    "\n",
    "class ConvolutionBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(ConvolutionBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Unet, self).__init__()\n",
    "        self.Convolution1 = ConvolutionBlock(in_ch, 64)  \n",
    "        self.maxpooling1 = nn.MaxPool2d(2)\n",
    "        self.Convolution2 = ConvolutionBlock(64, 128)\n",
    "        self.maxpooling2 = nn.MaxPool2d(2)\n",
    "        self.Convolution3 = ConvolutionBlock(128, 256)\n",
    "        self.maxpooling3 = nn.MaxPool2d(2)\n",
    "        self.Convolution4 = ConvolutionBlock(256, 512)\n",
    "        self.maxpooling4 = nn.MaxPool2d(2)\n",
    "        self.Convolution5 = ConvolutionBlock(512, 1024)\n",
    "\n",
    "        self.maxpooling6 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.Convolution6 = ConvolutionBlock(1024, 512)\n",
    "        self.maxpooling7 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.Convolution7 = ConvolutionBlock(512, 256)\n",
    "        self.maxpooling8 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.Convolution8 = ConvolutionBlock(256, 128)\n",
    "        self.maxpooling9 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.Convolution9 = ConvolutionBlock(128, 64)\n",
    "        self.Convolution10 = nn.Conv2d(64, out_ch, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.Convolution1(x)\n",
    "        pool1 = self.maxpooling1(conv1)\n",
    "        conv2 = self.Convolution2(pool1)\n",
    "        pool2 = self.maxpooling2(conv2)\n",
    "        conv3 = self.Convolution3(pool2)\n",
    "        pool3 = self.maxpooling3(conv3)\n",
    "        conv4 = self.Convolution4(pool3)\n",
    "        pool4 = self.maxpooling4(conv4)\n",
    "        conv5 = self.Convolution5(pool4)\n",
    "        up_6 = self.maxpooling6(conv5)\n",
    "        merge6 = torch.cat([up_6, conv4], dim=1)\n",
    "        conv6 = self.Convolution6(merge6)\n",
    "        up_7 = self.maxpooling7(conv6)\n",
    "        merge7 = torch.cat([up_7, conv3], dim=1)\n",
    "        conv7 = self.Convolution7(merge7)\n",
    "        up_8 = self.maxpooling8(conv7)\n",
    "        merge8 = torch.cat([up_8, conv2], dim=1)\n",
    "        conv8 = self.Convolution8(merge8)\n",
    "        up_9 = self.maxpooling9(conv8)\n",
    "        merge9 = torch.cat([up_9, conv1], dim=1)\n",
    "        conv9 = self.Convolution9(merge9)\n",
    "        conv10 = self.Convolution10(conv9)\n",
    "        out = nn.Softmax2d()(conv10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1637134517354,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "S63Q3gJxmt_b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 15350,
     "status": "ok",
     "timestamp": 1637134532700,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "217nb7U4m0xb"
   },
   "outputs": [],
   "source": [
    "unet = Unet(3,2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1637134533028,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "xViExA-wnNPr",
    "outputId": "28909758-cc91-4ee2-91f9-e93b23234a32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 512, 512]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 512, 512]             128\n",
      "              ReLU-3         [-1, 64, 512, 512]               0\n",
      "            Conv2d-4         [-1, 64, 512, 512]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 512, 512]             128\n",
      "              ReLU-6         [-1, 64, 512, 512]               0\n",
      "  ConvolutionBlock-7         [-1, 64, 512, 512]               0\n",
      "         MaxPool2d-8         [-1, 64, 256, 256]               0\n",
      "            Conv2d-9        [-1, 128, 256, 256]          73,856\n",
      "      BatchNorm2d-10        [-1, 128, 256, 256]             256\n",
      "             ReLU-11        [-1, 128, 256, 256]               0\n",
      "           Conv2d-12        [-1, 128, 256, 256]         147,584\n",
      "      BatchNorm2d-13        [-1, 128, 256, 256]             256\n",
      "             ReLU-14        [-1, 128, 256, 256]               0\n",
      " ConvolutionBlock-15        [-1, 128, 256, 256]               0\n",
      "        MaxPool2d-16        [-1, 128, 128, 128]               0\n",
      "           Conv2d-17        [-1, 256, 128, 128]         295,168\n",
      "      BatchNorm2d-18        [-1, 256, 128, 128]             512\n",
      "             ReLU-19        [-1, 256, 128, 128]               0\n",
      "           Conv2d-20        [-1, 256, 128, 128]         590,080\n",
      "      BatchNorm2d-21        [-1, 256, 128, 128]             512\n",
      "             ReLU-22        [-1, 256, 128, 128]               0\n",
      " ConvolutionBlock-23        [-1, 256, 128, 128]               0\n",
      "        MaxPool2d-24          [-1, 256, 64, 64]               0\n",
      "           Conv2d-25          [-1, 512, 64, 64]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-27          [-1, 512, 64, 64]               0\n",
      "           Conv2d-28          [-1, 512, 64, 64]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-30          [-1, 512, 64, 64]               0\n",
      " ConvolutionBlock-31          [-1, 512, 64, 64]               0\n",
      "        MaxPool2d-32          [-1, 512, 32, 32]               0\n",
      "           Conv2d-33         [-1, 1024, 32, 32]       4,719,616\n",
      "      BatchNorm2d-34         [-1, 1024, 32, 32]           2,048\n",
      "             ReLU-35         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-36         [-1, 1024, 32, 32]       9,438,208\n",
      "      BatchNorm2d-37         [-1, 1024, 32, 32]           2,048\n",
      "             ReLU-38         [-1, 1024, 32, 32]               0\n",
      " ConvolutionBlock-39         [-1, 1024, 32, 32]               0\n",
      "  ConvTranspose2d-40          [-1, 512, 64, 64]       2,097,664\n",
      "           Conv2d-41          [-1, 512, 64, 64]       4,719,104\n",
      "      BatchNorm2d-42          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-43          [-1, 512, 64, 64]               0\n",
      "           Conv2d-44          [-1, 512, 64, 64]       2,359,808\n",
      "      BatchNorm2d-45          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-46          [-1, 512, 64, 64]               0\n",
      " ConvolutionBlock-47          [-1, 512, 64, 64]               0\n",
      "  ConvTranspose2d-48        [-1, 256, 128, 128]         524,544\n",
      "           Conv2d-49        [-1, 256, 128, 128]       1,179,904\n",
      "      BatchNorm2d-50        [-1, 256, 128, 128]             512\n",
      "             ReLU-51        [-1, 256, 128, 128]               0\n",
      "           Conv2d-52        [-1, 256, 128, 128]         590,080\n",
      "      BatchNorm2d-53        [-1, 256, 128, 128]             512\n",
      "             ReLU-54        [-1, 256, 128, 128]               0\n",
      " ConvolutionBlock-55        [-1, 256, 128, 128]               0\n",
      "  ConvTranspose2d-56        [-1, 128, 256, 256]         131,200\n",
      "           Conv2d-57        [-1, 128, 256, 256]         295,040\n",
      "      BatchNorm2d-58        [-1, 128, 256, 256]             256\n",
      "             ReLU-59        [-1, 128, 256, 256]               0\n",
      "           Conv2d-60        [-1, 128, 256, 256]         147,584\n",
      "      BatchNorm2d-61        [-1, 128, 256, 256]             256\n",
      "             ReLU-62        [-1, 128, 256, 256]               0\n",
      " ConvolutionBlock-63        [-1, 128, 256, 256]               0\n",
      "  ConvTranspose2d-64         [-1, 64, 512, 512]          32,832\n",
      "           Conv2d-65         [-1, 64, 512, 512]          73,792\n",
      "      BatchNorm2d-66         [-1, 64, 512, 512]             128\n",
      "             ReLU-67         [-1, 64, 512, 512]               0\n",
      "           Conv2d-68         [-1, 64, 512, 512]          36,928\n",
      "      BatchNorm2d-69         [-1, 64, 512, 512]             128\n",
      "             ReLU-70         [-1, 64, 512, 512]               0\n",
      " ConvolutionBlock-71         [-1, 64, 512, 512]               0\n",
      "           Conv2d-72          [-1, 2, 512, 512]             130\n",
      "================================================================\n",
      "Total params: 31,043,586\n",
      "Trainable params: 31,043,586\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 3720.00\n",
      "Params size (MB): 118.42\n",
      "Estimated Total Size (MB): 3841.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(unet,(3,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1637135452933,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "QLrU2D71n3Po"
   },
   "outputs": [],
   "source": [
    "#Utility functions\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[.5,.5,0.5],std=[.5,.5,0.5]) \n",
    "])\n",
    "\n",
    "def cal_iou(model, dataset):\n",
    "    pa=mpa=miou=fwiou=0.\n",
    "    for img, mask in dataset:\n",
    "        mask = mask.cuda()\n",
    "        with torch.no_grad():\n",
    "            pred = model(img.unsqueeze(0).cuda())\n",
    "            pred = torch.argmax(pred, 1).float()\n",
    "        pa += get_pa(pred, mask)\n",
    "        mpa += get_mpa(pred, mask)\n",
    "        miou += get_miou(pred, mask)\n",
    "        fwiou += get_fwiou(pred, mask)\n",
    "    lenth = len(dataset)\n",
    "    pa /= lenth\n",
    "    mpa /= lenth\n",
    "    miou /= lenth\n",
    "    fwiou /= lenth\n",
    "    return pa.item(), mpa.item(), miou.item(), fwiou.item()\n",
    "\n",
    "def get_pa(pred, mask):\n",
    "    return (pred==mask).sum().float()/(512*512)\n",
    "\n",
    "\n",
    "def get_mpa(pred, mask):\n",
    "    pred_crack = pred\n",
    "    pred_fine = 1-pred\n",
    "    mask_crack = mask\n",
    "    mask_fine = 1-mask\n",
    "    return (pred_crack*mask_crack).sum().float()/\\\n",
    "            (mask_crack.sum())/2 +\\\n",
    "            (pred_fine*mask_fine).sum().float()/\\\n",
    "            (mask_fine.sum())/2\n",
    "\n",
    "\n",
    "def get_miou(pred, mask):\n",
    "\n",
    "    pred_crack = pred\n",
    "    pred_fine = 1-pred\n",
    "    mask_crack = mask\n",
    "    mask_fine = 1-mask\n",
    "    return (pred_crack*mask_crack).sum().float()/\\\n",
    "            ((mask_crack+pred_crack)!=0).sum()/2+\\\n",
    "            (pred_fine*mask_fine).sum().float()/\\\n",
    "            ((mask_fine+pred_fine)!=0).sum()/2\n",
    "\n",
    "\n",
    "def get_fwiou(pred, mask):\n",
    "    pred_crack = pred\n",
    "    pred_fine = 1-pred\n",
    "    mask_crack = mask\n",
    "    mask_fine = 1-mask\n",
    "    return  mask_crack.sum()*(pred_crack*mask_crack).sum().float()/\\\n",
    "            ((mask_crack+pred_crack)!=0).sum()/(512*512)+\\\n",
    "            mask_fine.sum()*(pred_fine*mask_fine).sum().float()/\\\n",
    "            ((mask_fine+pred_fine)!=0).sum()/(512*512)\n",
    "\n",
    "\n",
    "def onehot(masks):\n",
    "    masks_t = torch.zeros(masks.size(0), 2, \n",
    "                    masks.size(2), masks.size(3)).cuda()\n",
    "    masks_t[:,0,:,:][masks[:,0,:,:]==0] = 1\n",
    "    masks_t[:,1,:,:][masks[:,0,:,:]==1] = 1   \n",
    "    return masks_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "executionInfo": {
     "elapsed": 1052868,
     "status": "error",
     "timestamp": 1637136721018,
     "user": {
      "displayName": "Abhinav Reddy Nimma",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15129220168546697775"
     },
     "user_tz": -60
    },
    "id": "ai7aOrdAoSb1",
    "outputId": "f87ba6aa-153f-491f-9c99-7f620c063157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss function:  bce  & Optimiser:  adam\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0923164d1822>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoidx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mtotalloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    877\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m             \u001b[1;31m# request that overlapped reads stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "import logging\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = [30]\n",
    "num_workers = 2\n",
    "lr = 0.0001\n",
    "\n",
    "losslist = [ 'bce'] #can iterate through multiple losses, for final report\n",
    "optimlist = ['adam'] #can iterate through multiple optimisers, for final report\n",
    "iflog = True\n",
    "\n",
    "train_dataset = myDataset('data/train', transform=transform)\n",
    "val_dataset = myDataset('data/val', transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=num_workers)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=1,\n",
    "                            shuffle=False)\n",
    "criterion = nn.BCELoss()\n",
    "focallos = FocalLoss(gamma=2)\n",
    "\n",
    "epoidx = -1\n",
    "for los in losslist:\n",
    "    for opt in optimlist:\n",
    "        start =  time.time()\n",
    "        print(\"Using loss function: \",los,\" & Optimiser: \", opt)\n",
    "        torch.manual_seed(77)\n",
    "        torch.cuda.manual_seed(77)\n",
    "        unet = Unet(3,2).cuda()\n",
    "        history = []\n",
    "        if 'adam' in opt :\n",
    "            optimizer = torch.optim.Adam(unet.parameters(), lr=lr)\n",
    "        elif 'sgd' in opt:\n",
    "            optimizer = torch.optim.SGD(unet.parameters(), lr=10*lr, momentum=0.9)\n",
    "\n",
    "        logging.basicConfig(filename='./logs/logger_unet.log', level=logging.INFO)\n",
    "\n",
    "        total_step = len(train_loader)\n",
    "        epoidx += 1\n",
    "        for epoch in range(num_epochs[epoidx]):\n",
    "            totalloss = 0\n",
    "            for i, (images, masks) in enumerate(train_loader):\n",
    "                images = images.cuda()\n",
    "                masks = masks.cuda()\n",
    "                outputs = unet(images)\n",
    "                if 'bce' in los :\n",
    "                    masks = onehot(masks)              \n",
    "                    loss = criterion(outputs, masks)\n",
    "                elif 'dice' in los :\n",
    "                    masks = onehot(masks)              \n",
    "                    loss = dice_loss(outputs, masks)\n",
    "                elif 'lovasz' in los :\n",
    "                    masks = onehot(masks)          \n",
    "                    loss = L.lovasz_hinge(outputs, masks)\n",
    "                elif 'focal' in los :\n",
    "                    loss = focallos(outputs, masks.long())\n",
    "\n",
    "                totalloss += loss*images.size(0)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #print(\"epoch : \", epoch, \"Loss: \",totalloss)\n",
    "                if i+1 == total_step:\n",
    "                    train_pa, train_mpa, train_miou, train_fwiou = \\\n",
    "                                        cal_iou(unet,train_dataset)\n",
    "                    val_pa, val_mpa, val_miou, val_fwiou = \\\n",
    "                                        cal_iou(unet,val_dataset)\n",
    "                    history.append([totalloss.item()/len(train_dataset), \n",
    "                                    train_pa, train_mpa, train_miou, train_fwiou,\n",
    "                                    val_pa, val_mpa, val_miou, val_fwiou])\n",
    "                \n",
    "                if  i+1 == total_step and epoch%3==0 and val_miou>0.8 :\n",
    "                    print(\"Saving the model at Epoch \",str(epoch+1),\" with Val IOU \",str(val_miou))\n",
    "                    torch.save(unet.state_dict(), \n",
    "                                './trained_models/unet_'+opt+'_'+los+'_'+str(epoch+1)+'.pkl')\n",
    "                    print(\"Model saved : \")\n",
    "\n",
    "            print(\"Epoch: \", epoch, \" Loss: \",totalloss.item()/len(train_dataset), \"Validation IOU: \", val_miou)\n",
    "            history_np = np.array(history)\n",
    "            np.save('./logs/unet_'+opt+'_'+los+'.npy',history_np)\n",
    "        end = time.time()\n",
    "        print((\"Total time taken for training : \",(end-start)/60,\" Minutes\"))\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJ7VKJGCo-FT"
   },
   "outputs": [],
   "source": [
    "#from torchvision import models\n",
    "#print(unet) #i do not know if this works yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LBeVkLXAvrp6"
   },
   "outputs": [],
   "source": [
    "torch.save(unet.state_dict(), './trained_models/unet_adam_bce_final.pkl') #save the final model, just as final check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "d6kGhkicBl56"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'isic2018_100_20_30_data/test/images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1659ae187f99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mimg_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'isic2018_100_20_30_data/test/images/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mimg_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mimg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'isic2018_100_20_30_data/test/images/'"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.manual_seed(777)\n",
    "torch.manual_seed(777)\n",
    "\n",
    "img_folder = 'isic2018_100_20_30_data/test/images/'\n",
    "img_dir = os.listdir(img_folder)\n",
    "img_list = [img_folder+k for k in img_dir]\n",
    "img_list.sort()\n",
    "\n",
    "unet = Unet(3,2).cuda()\n",
    "unet.load_state_dict(torch.load('isic2018_100_20_30_trained_models/unet_'+opt+'_'+los+'_'+'final'+'.pkl'))\n",
    "\n",
    "\n",
    "for file in img_list:\n",
    "    img = Image.open(file).resize([512,512])\n",
    "    img = transform(img).cuda().unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        pred = unet(img)\n",
    "    pred = torch.argmin(pred,1)\n",
    "    pred = pred.squeeze().cpu().numpy()\n",
    "    pred = np.uint8(pred*255)\n",
    "    pred_img = Image.fromarray(pred)\n",
    "    img_name = str.split(file, '/')[-1]\n",
    "    \n",
    "    img_name = 'isic2018_100_20_30_data/test/unet_pred/' + img_name\n",
    "    pred_img.save(img_name, 'png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyqJVmjNBwwq"
   },
   "outputs": [],
   "source": [
    "#Concattenate Test Image, Ground Truth, Predicted Mask,\n",
    "\n",
    "for image in os.listdir(\"isic2018_100_20_30_data/test/images\") :\n",
    "  #print(image)\n",
    "  original = PIL.Image.open(\"isic2018_100_20_30_data/test/images/\"+image)\n",
    "  #print(original)\n",
    "  print(image.split(\".png\")[0]+\"_segmentation.png\")\n",
    "  groundTruth = PIL.Image.open(\"isic2018_100_20_30_data/test/masks/\"+image.split(\".jpg\")[0]+\"_segmentation.png\")\n",
    "  unetPrediction = PIL.Image.open(\"isic2018_100_20_30_data/test/unet_pred/\"+image)\n",
    "  concat = PIL.Image.new('RGB',(original.width + groundTruth.width + unetPrediction.width, original.height))\n",
    "  concat.paste(original,(0,0))\n",
    "  concat.paste(groundTruth,(original.width,0))\n",
    "  concat.paste(groundTruth,(original.width + groundTruth.width,0))\n",
    "  concat.save(\"isic2018_100_20_30_data/test/results/\"+image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugZNtK3KCB7a"
   },
   "outputs": [],
   "source": [
    "concat #check one image"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNkFVxNgsGHcmozsaJR2ozB",
   "collapsed_sections": [],
   "mount_file_id": "1CLtnqoiIcMSdAypgOtIy-oqBPsuLbFmY",
   "name": "ISIC_Segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
